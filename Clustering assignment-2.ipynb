{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f54e99-f37c-43be-bded-f4a6ff7d4536",
   "metadata": {},
   "source": [
    "Hedger clustering is a clustering techniques that combines hiaechial clusteringg and k-means clustering it starts by using hiaechial clustering to create an intial set of clusters and then applies k means clustering to refine them.The main diffrence between hedger clustering and other clustering techniques lies in its hybrid apporach tradtional hiearchial clustering method build a tree-like structure of cluster based on the similarity between data points while k-means clustering partions data into a predetrmined number of clusster based on the mean distance between point and cluster centroids hedger clustering aims to levrage the strength of both method to acheive more \n",
    "accurate and stable clusterings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48466cc-888e-4287-9968-aec0dab01e13",
   "metadata": {},
   "source": [
    "The two main types of hierchial clustering algorthims are:\n",
    "1. Spiral-based clutering:Thus algorthims identifies cluster in datasets that exhibt a spiral or helical structure  it typically involves techniques such as density estimation where points closed together in the spiral structure are assigned higer density values and clustering algorthims like DBSCAN or OPTICS to group point with similar densties into cluster.\n",
    "2. Helix-based clustering:This apporach is spherically tailored for datsets with a helical structure it often involves modeling the helical shape explcity and then fitting data points to this model to determine cluster assignment.Technique suach as least square fitting or probablistic models may be used to fit the helix to the data these algorthims aim to identify clusterr along the helical path in the dataet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae5651a-935d-476d-af9a-b32f3115aa63",
   "metadata": {},
   "source": [
    "In hiearchial fuzzy clustering the distance between two cluster is determined based on the distance between their respective cluster centroid or the memmership value of their data point commonly used distance metric for determiniing used distance between cluster include:\n",
    "1. Euclidean distance:Measure the straight line distance between two pints in Euclidean space it is commonly used distance metric in clustering algorthims.\n",
    "2. Manhattan distance:Also know as city block distance or L1 distance it measure the sum of the absolute diffrences between the coordinates of two pints.\n",
    "3. Minikowski distance: A genralization of both Euclidean and manhattan distamces where the distance between two points is given up by pth root of the sum of the absolute diffrence raised to power of p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20dd8e3-9cc3-4b61-afbb-c133f2fcbc2e",
   "metadata": {},
   "source": [
    "Determing the optimal number of cluster in high richer clustering can be challenging but is cruicial for obtaning meaniingful result sevral common method used for this purpose include:\n",
    "1. Elbow method: This method involves plottingg the within -cluster sum of square against the number of cluster and looking for the elbow point where the rate of decrease in WCSS slows down this point indicate a suitable number of clusters\n",
    "2. Silhouette analysis: Silhouette analysis measure how similar an object is to own cluster compared to other cluster it  produce a silhouette score for each data point and the average silhouette score across all data point can be used to determined the optimal number of cluster\n",
    "3. Gap statistic: The gap statistic compares the within the winner cluster dispersion to that expected under  a null refrence ditribution of the data the optimal number of clusterr in the value that maximizes the gap ststicts.\n",
    "4. Dravies bouldin index:This index measure the average similarity between each clister and its mostt similar clsuter where similarity is defined in terms pf intra cluster and inter cluster  so the number clustering so that number of clustre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebf83f4-0d3f-4cc8-a7e6-99a29aae35d8",
   "metadata": {},
   "source": [
    "In high-risk clustering dendrogram are hierchial tree-like structure that visualy reprsent the result of the clusterring process thay display the relationship between data points cluster by iilustrating the merging and splitting of cluster at each stage of hiearchial clustering algorthims:\n",
    "1. Cluster identification\n",
    "2. Cluster interpretation\n",
    "3. Determining the optimal number cluster\n",
    "4. understanding cluster relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea0c43-f7d9-4c34-a333-d34f49a936d2",
   "metadata": {},
   "source": [
    "Hierachial clustering can be used to identify outliers or anomalies in data by examining the structure of the dendrogram and observing datapoints that are clustered seprately or form small isolated cluster here how you can use hierchial clustering for outlier detection:\n",
    "1. Distance from cluster\n",
    "2. height of mergining\n",
    "3. cluster size and density\n",
    "4. Silhouette analysis\n",
    "By levarging the hierchial structure of the clustering result and examining the distribution and relationship of data point within cluster h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
